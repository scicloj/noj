[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scinojure Documentation",
    "section": "",
    "text": "1 Preface\nScinojure (‚ÄúNoj‚Äù) is an entry point to the Clojure stack for data & science.\nIt combines a few of the relevant Clojure libraries for data & science and documents common ways of using them together. The included libraries either use tech.ml.dataset directly as tabular data structure or provide high interoperability with it.\nSource:\nDeps:\nTests:\nNote we are using git coordinates at the moment, in order to expose a few relevant features of the current underlying libraries, which are unreleased yet.\nStatus: Most of the underlying libraries are stable. The experimental parts are marked as such. For some of the libraries, we use a branch for an upcoming release. The main current goal is to provide a clear picture of the direction the stack is going towards, expecting most of it to stabilize soon.\nNear term plan - till the end of October 2024",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "index.html#chapters-of-this-book",
    "href": "index.html#chapters-of-this-book",
    "title": "Scinojure Documentation",
    "section": "1.1 Chapters of this book:",
    "text": "1.1 Chapters of this book:\n\nOverview\n\nUnderlying libraries\nRecommended libraries\nKnown issues ‚ùó\n\nTutorials\n\nDatasets\nMachine learning\nMachine learning specific functionality in tech.ml.dataset\nAutoML using metamorph pipelines\nOrdinary least squares with interactions\nVisualizing correlation matrices (experimental üõ†) - DRAFT\n\n\n\nsource: notebooks/index.clj",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "noj_book.underlying_libraries.html",
    "href": "noj_book.underlying_libraries.html",
    "title": "2¬† Underlying libraries",
    "section": "",
    "text": "Noj consists of the following libraries:\n\nTablecloth - dataset processing on top of TMD\ntcutils - utility functions for Tablecloth datasets - üõ† early stage\ntech.ml.dataset (TMD) - high-perfrormance table processing\ntmd-parquet - TMD bindings for Parquet format\ndtype-next - high-performance array-programming\nKindly - datavis standard\nFastmath - math & stats - alpha stage of version 3\nHanamicloth - easy layered graphics - üõ† alpha version - should stabilize soon\nHanami - interactive datavis\nmetamorph.ml - machine learning platform\nscicloj.ml.tribuo - Tribuo machine learning models\nscicloj.ml.smile - Smile (v 2.6) machine learning models\nsklearn-clj -\nsome Tribuo modules added by default: general-linear and tree ensembles for regression/classification\nlibpython-clj - Python bindings\nkind-pyplot - Python plotting\nClojisR - R bindings\nsame-ish - approximate comparisons - useful for notebook testability\n\n\nsource: notebooks/noj_book/underlying_libraries.clj",
    "crumbs": [
      "Overview",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Underlying libraries</span>"
    ]
  },
  {
    "objectID": "noj_book.recommended_libraries.html",
    "href": "noj_book.recommended_libraries.html",
    "title": "3¬† Recommended libraries",
    "section": "",
    "text": "We recommend combining Noj with the following libraries:\n\nWolframite - Wolfram Language bindings\ncljplot - plotting - üõ† early stage\nkixi.stats - statistics with transducers\nfitdistr - fitting distributions\ninferme - Bayesian inference\ncmdstan-clj - bindings for Stan Bayesian inference - üõ† early stage\nfastmath-clustering - a wrapper for Smile 2.6 clustering algorithms\nclj-djl - bindings for Deep Java Library\nscicloj.ml.clj-djl - clj-djl models for metamorph.ml\nNeanderthal - high-performance numerical computing\nmatlib - optimisation and control theory with Neanderthal\ndeep-diamond - tensors & deep learning\nllama.clj - running LLMs locally\nBosquet - tooling for LLM applications\n\n\nsource: notebooks/noj_book/recommended_libraries.clj",
    "crumbs": [
      "Overview",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Recommended libraries</span>"
    ]
  },
  {
    "objectID": "noj_book.known_issues.html",
    "href": "noj_book.known_issues.html",
    "title": "4¬† Known issues ‚ùó",
    "section": "",
    "text": "(currently none)\n\nsource: notebooks/noj_book/known_issues.clj",
    "crumbs": [
      "Overview",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Known issues ‚ùó</span>"
    ]
  },
  {
    "objectID": "noj_book.datasets.html",
    "href": "noj_book.datasets.html",
    "title": "5¬† Datasets",
    "section": "",
    "text": "author: Daniel Slutsky\n\n(ns noj-book.datasets\n  (:require [tablecloth.api :as tc]))\n\nFor our tutorials here, let us fetch some datasets from Rdatasets\n\n(def iris\n  (-&gt; \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv\"\n      (tc/dataset {:key-fn keyword})\n      (tc/rename-columns {:Sepal.Length :sepal-length\n                          :Sepal.Width :sepal-width\n                          :Petal.Length :petal-length\n                          :Petal.Width :petal-width\n                          :Species :species})))\n\n\niris\n\n\nhttps://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv [150 6]:\n\n\n\n\n\n\n\n\n\n\n\n:rownames\n:sepal-length\n:sepal-width\n:petal-length\n:petal-width\n:species\n\n\n\n\n1\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n2\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n3\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n6\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n7\n4.6\n3.4\n1.4\n0.3\nsetosa\n\n\n8\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n9\n4.4\n2.9\n1.4\n0.2\nsetosa\n\n\n10\n4.9\n3.1\n1.5\n0.1\nsetosa\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n140\n6.9\n3.1\n5.4\n2.1\nvirginica\n\n\n141\n6.7\n3.1\n5.6\n2.4\nvirginica\n\n\n142\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n143\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n144\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n145\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n146\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n147\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n148\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n149\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n150\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n\n(def mtcars\n  (-&gt; \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\"\n      (tc/dataset {:key-fn keyword})))\n\n\nmtcars\n\n\nhttps://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv [32 12]:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:rownames\n:mpg\n:cyl\n:disp\n:hp\n:drat\n:wt\n:qsec\n:vs\n:am\n:gear\n:carb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n\nsource: notebooks/noj_book/datasets.clj",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "noj_book.ml_basic.html",
    "href": "noj_book.ml_basic.html",
    "title": "6¬† Machine learning",
    "section": "",
    "text": "6.1 Inspect data\nThe titanic data is part of metamorph.ml and in the form of a train, test split\nWe use the :train part only for this tutorial.\nWe use defonce to avoid reading the files every time we evaluate the namespace.\nIt has various columns\nof which we can get some statistics\nThe data is more or less balanced across the 2 classes:\nWe will make a very simple model, which will predict the column :survived from columns :sex , :pclass and :embarked. These represent the ‚Äúgender‚Äù, ‚Äúpassenger class‚Äù and ‚Äúport of embarkment‚Äù.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "noj_book.ml_basic.html#inspect-data",
    "href": "noj_book.ml_basic.html#inspect-data",
    "title": "6¬† Machine learning",
    "section": "",
    "text": "(-&gt;\n (data/titanic-ds-split)\n :train)\n\n\n_unnamed [891 12]:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:passenger-id\n:survived\n:pclass\n:name\n:sex\n:age\n:sib-sp\n:parch\n:ticket\n:fare\n:cabin\n:embarked\n\n\n\n\n1\n0\n3\nBraund, Mr.¬†Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\n\nS\n\n\n2\n1\n1\nCumings, Mrs.¬†John Bradley (Florence Briggs Thayer)\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\n\nS\n\n\n4\n1\n1\nFutrelle, Mrs.¬†Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n5\n0\n3\nAllen, Mr.¬†William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\n\nS\n\n\n6\n0\n3\nMoran, Mr.¬†James\nmale\n\n0\n0\n330877\n8.4583\n\nQ\n\n\n7\n0\n1\nMcCarthy, Mr.¬†Timothy J\nmale\n54.0\n0\n0\n17463\n51.8625\nE46\nS\n\n\n8\n0\n3\nPalsson, Master. Gosta Leonard\nmale\n2.0\n3\n1\n349909\n21.0750\n\nS\n\n\n9\n1\n3\nJohnson, Mrs.¬†Oscar W (Elisabeth Vilhelmina Berg)\nfemale\n27.0\n0\n2\n347742\n11.1333\n\nS\n\n\n10\n1\n2\nNasser, Mrs.¬†Nicholas (Adele Achem)\nfemale\n14.0\n1\n0\n237736\n30.0708\n\nC\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n881\n1\n2\nShelley, Mrs.¬†William (Imanita Parrish Hall)\nfemale\n25.0\n0\n1\n230433\n26.0000\n\nS\n\n\n882\n0\n3\nMarkun, Mr.¬†Johann\nmale\n33.0\n0\n0\n349257\n7.8958\n\nS\n\n\n883\n0\n3\nDahlberg, Miss. Gerda Ulrika\nfemale\n22.0\n0\n0\n7552\n10.5167\n\nS\n\n\n884\n0\n2\nBanfield, Mr.¬†Frederick James\nmale\n28.0\n0\n0\nC.A./SOTON 34068\n10.5000\n\nS\n\n\n885\n0\n3\nSutehall, Mr.¬†Henry Jr\nmale\n25.0\n0\n0\nSOTON/OQ 392076\n7.0500\n\nS\n\n\n886\n0\n3\nRice, Mrs.¬†William (Margaret Norton)\nfemale\n39.0\n0\n5\n382652\n29.1250\n\nQ\n\n\n887\n0\n2\nMontvila, Rev.¬†Juozas\nmale\n27.0\n0\n0\n211536\n13.0000\n\nS\n\n\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n889\n0\n3\nJohnston, Miss. Catherine Helen ‚ÄúCarrie‚Äù\nfemale\n\n1\n2\nW./C. 6607\n23.4500\n\nS\n\n\n890\n1\n1\nBehr, Mr.¬†Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n891\n0\n3\nDooley, Mr.¬†Patrick\nmale\n32.0\n0\n0\n370376\n7.7500\n\nQ\n\n\n\n\n\n\n(defonce titanic-split\n  (data/titanic-ds-split))\n\n\n(def titanic\n  (-&gt; titanic-split\n      :train\n      (tc/map-columns :survived\n                      [:survived]\n                      (fn [el] (case el\n                                 0 \"no\"\n                                 1 \"yes\")))))\n\n\n\n(tc/column-names titanic)\n\n\n(:passenger-id\n :survived\n :pclass\n :name\n :sex\n :age\n :sib-sp\n :parch\n :ticket\n :fare\n :cabin\n :embarked)\n\n\n\n(ds/descriptive-stats titanic)\n\n\n_unnamed: descriptive-stats [12 12]:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:col-name\n:datatype\n:n-valid\n:n-missing\n:min\n:mean\n:mode\n:max\n:standard-deviation\n:skew\n:first\n:last\n\n\n\n\n:passenger-id\n:int16\n891\n0\n1.00\n446.00000000\n\n891.0000\n257.35384202\n0.00000000\n1\n891\n\n\n:survived\n:string\n891\n0\n\n\nno\n\n\n\nno\nno\n\n\n:pclass\n:int16\n891\n0\n1.00\n2.30864198\n\n3.0000\n0.83607124\n-0.63054791\n3\n3\n\n\n:name\n:string\n891\n0\n\n\nMallet, Mr.¬†Albert\n\n\n\nBraund, Mr.¬†Owen Harris\nDooley, Mr.¬†Patrick\n\n\n:sex\n:string\n891\n0\n\n\nmale\n\n\n\nmale\nmale\n\n\n:age\n:float64\n714\n177\n0.42\n29.69911765\n\n80.0000\n14.52649733\n0.38910778\n22.00\n32.00\n\n\n:sib-sp\n:int16\n891\n0\n0.00\n0.52300786\n\n8.0000\n1.10274343\n3.69535173\n1\n0\n\n\n:parch\n:int16\n891\n0\n0.00\n0.38159371\n\n6.0000\n0.80605722\n2.74911705\n0\n0\n\n\n:ticket\n:string\n891\n0\n\n\nCA. 2343\n\n\n\nA/5 21171\n370376\n\n\n:fare\n:float64\n891\n0\n0.00\n32.20420797\n\n512.3292\n49.69342860\n4.78731652\n7.250\n7.750\n\n\n:cabin\n:string\n204\n687\n\n\n\n\n\n\n\n\n\n\n:embarked\n:string\n889\n2\n\n\nS\n\n\n\nS\nQ\n\n\n\n\n\n\n(-&gt; titanic :survived frequencies)\n\n\n{\"no\" 549, \"yes\" 342}\n\n\n\n(def categorical-feature-columns [:sex :pclass :embarked])\n\n\n(def target-column :survived)",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "noj_book.ml_basic.html#convert-categorical-features-to-numeric",
    "href": "noj_book.ml_basic.html#convert-categorical-features-to-numeric",
    "title": "6¬† Machine learning",
    "section": "6.2 Convert categorical features to numeric",
    "text": "6.2 Convert categorical features to numeric\nAs we need to convert the non numerical feature columns to categorical, we will first look at their unique values:\n\n(map\n #(hash-map\n   :col-name %\n   :values  (distinct (get titanic %)))\n categorical-feature-columns)\n\n\n({:col-name :sex, :values (\"male\" \"female\")}\n {:col-name :pclass, :values (3 1 2)}\n {:col-name :embarked, :values (\"S\" \"C\" \"Q\" nil)})\n\nThis allows us now to set specifically the values in the conversion to numbers. This is a good practice, instead of the relying on the automatic selection of the categorical mapping:\n(We discuss more about categorical mappings in another chapter.)\n\n(require '[tech.v3.dataset.categorical :as ds-cat]\n         '[tech.v3.dataset.modelling :as ds-mod]\n         '[tech.v3.dataset.column-filters :as cf])\n\nThis gives then the selected and numeric columns like this:\n\n(def relevant-titanic-data\n  (-&gt; titanic\n      (tc/select-columns (conj categorical-feature-columns target-column))\n      (tc/drop-missing)\n      (ds/categorical-&gt;number [:survived] [\"no\" \"yes\"] :float64)\n      (ds-mod/set-inference-target target-column)))\n\nof which we can inspect the lookup-tables\n\n(def cat-maps\n  [(ds-cat/fit-categorical-map relevant-titanic-data :sex [\"male\" \"female\"] :float64)\n   (ds-cat/fit-categorical-map relevant-titanic-data :pclass [0 1 2] :float64)\n   (ds-cat/fit-categorical-map relevant-titanic-data :embarked [\"S\" \"Q\" \"C\"] :float64)])\n\n\ncat-maps\n\n\n[{:lookup-table {\"male\" 0, \"female\" 1},\n  :src-column :sex,\n  :result-datatype :float64}\n {:lookup-table {0 0, 1 1, 2 2, 3 3},\n  :src-column :pclass,\n  :result-datatype :float64}\n {:lookup-table {\"S\" 0, \"Q\" 1, \"C\" 2},\n  :src-column :embarked,\n  :result-datatype :float64}]\n\nAfter the mappings are applied, we have a numeric dataset, as expected by most models.\n\n(def numeric-titanic-data\n  (reduce (fn [ds cat-map]\n            (ds-cat/transform-categorical-map ds cat-map))\n          relevant-titanic-data\n          cat-maps))\n\n\n(tc/head\n numeric-titanic-data)\n\n\n_unnamed [5 4]:\n\n\n\n:sex\n:pclass\n:embarked\n:survived\n\n\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n1.0\n2.0\n1.0\n\n\n1.0\n3.0\n0.0\n1.0\n\n\n1.0\n1.0\n0.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n\n\n\n(ds/rowvecs\n (tc/head\n  numeric-titanic-data))\n\n\n[[0.0 3.0 0.0 0.0] [1.0 1.0 2.0 1.0] [1.0 3.0 0.0 1.0] [1.0 1.0 0.0 1.0] [0.0 3.0 0.0 0.0]]\n\nSplit data into train and test set Now we split the data into train and test. By we use a :holdout strategy, so will get a single split in training an test data.\n\n(def split\n  (first\n   (tc/split-&gt;seq numeric-titanic-data :holdout {:seed 112723})))\n\n\nsplit\n\n{\n\n\n\n\n\n\n\n\n:train\n\n\n\nGroup: 0 [592 4]:\n\n\n\n:sex\n:pclass\n:embarked\n:survived\n\n\n\n\n0.0\n3.0\n2.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n3.0\n2.0\n1.0\n\n\n0.0\n1.0\n0.0\n0.0\n\n\n1.0\n3.0\n0.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n1.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n1.0\n2.0\n1.0\n\n\n...\n...\n...\n...\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n0.0\n3.0\n2.0\n1.0\n\n\n1.0\n2.0\n0.0\n0.0\n\n\n0.0\n2.0\n0.0\n0.0\n\n\n1.0\n3.0\n0.0\n1.0\n\n\n0.0\n2.0\n0.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n0.0\n3.0\n0.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n1.0\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:test\n\n\n\nGroup: 0 [297 4]:\n\n\n\n:sex\n:pclass\n:embarked\n:survived\n\n\n\n\n0.0\n1.0\n0.0\n0.0\n\n\n1.0\n3.0\n0.0\n0.0\n\n\n0.0\n2.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n3.0\n2.0\n1.0\n\n\n0.0\n1.0\n2.0\n0.0\n\n\n...\n...\n...\n...\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n3.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n2.0\n2.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n1.0\n\n\n0.0\n1.0\n0.0\n0.0\n\n\n1.0\n1.0\n2.0\n1.0\n\n\n\n\n\n\n\n\n}",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "noj_book.ml_basic.html#train-a-model",
    "href": "noj_book.ml_basic.html#train-a-model",
    "title": "6¬† Machine learning",
    "section": "6.3 Train a model",
    "text": "6.3 Train a model\nNow its time to train a model.\n\n(require '[scicloj.metamorph.ml :as ml]\n         '[scicloj.metamorph.ml.classification]\n         '[scicloj.metamorph.ml.loss :as loss])\n\n\n6.3.1 Dummy model\nWe start with a dummy model, which simply predicts the majority class\n\n(def dummy-model (ml/train (:train split)\n                           {:model-type :metamorph.ml/dummy-classifier}))\n\nTODO: Is the dummy model wrong about the majority?\n\n(def dummy-prediction\n  (ml/predict (:test split) dummy-model))\n\nIt always predicts a single class, as expected:\n\n(-&gt; dummy-prediction :survived frequencies)\n\n\n{1.0 297}\n\nwe can calculate accuracy by using a metric after having converted the numerical data back to original (important !) We should never compare mapped columns directly.\n\n(loss/classification-accuracy\n (:survived (ds-cat/reverse-map-categorical-xforms (:test split)))\n (:survived (ds-cat/reverse-map-categorical-xforms dummy-prediction)))\n\n\n0.3973063973063973\n\nIt‚Äôs performance is poor, even worse than coin flip.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "noj_book.ml_basic.html#logistic-regression",
    "href": "noj_book.ml_basic.html#logistic-regression",
    "title": "6¬† Machine learning",
    "section": "6.4 Logistic regression",
    "text": "6.4 Logistic regression\nNext model to use is Logistic Regression\n\n(require '[scicloj.ml.tribuo])\n\n\n(def lreg-model (ml/train (:train split)\n                          {:model-type :scicloj.ml.tribuo/classification\n                           :tribuo-components [{:name \"logistic\"\n                                                :type \"org.tribuo.classification.sgd.linear.LinearSGDTrainer\"}]\n                           :tribuo-trainer-name \"logistic\"}))\n\n\n(def lreg-prediction\n  (ml/predict (:test split) lreg-model))\n\n\n(loss/classification-accuracy\n (:survived (ds-cat/reverse-map-categorical-xforms (:test split)))\n (:survived  lreg-prediction))\n\n\n0.7373737373737373\n\nIts performance is better, 73 %",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "noj_book.ml_basic.html#random-forest",
    "href": "noj_book.ml_basic.html#random-forest",
    "title": "6¬† Machine learning",
    "section": "6.5 Random forest",
    "text": "6.5 Random forest\nNext is random forest\n\n(def rf-model (ml/train (:train split) {:model-type :scicloj.ml.tribuo/classification\n                                        :tribuo-components [{:name \"random-forest\"\n                                                             :type \"org.tribuo.classification.dtree.CARTClassificationTrainer\"\n                                                             :properties {:maxDepth \"8\"\n                                                                          :useRandomSplitPoints \"false\"\n                                                                          :fractionFeaturesInSplit \"0.5\"}}]\n                                        :tribuo-trainer-name \"random-forest\"}))\n\n\n(def rf-prediction\n  (ml/predict (:test split) rf-model))\n\nFirst five prediction including the probability distributions are\n\n(-&gt; rf-prediction\n    (tc/head)\n    (tc/rows))\n\n\n[[\"no\" 0.6470588235294118 0.35294117647058826] [\"no\" 0.5714285714285714 0.42857142857142855] [\"no\" 0.8529411764705882 0.14705882352941177] [\"no\" 0.8879310344827587 0.11206896551724138] [\"no\" 0.8879310344827587 0.11206896551724138]]\n\n\n(loss/classification-accuracy\n (:survived (ds-cat/reverse-map-categorical-xforms (:test split)))\n (:survived (ds-cat/reverse-map-categorical-xforms rf-prediction)))\n\n\n0.7878787878787878\n\nbest so far, 78 %\nTODO: Extract feature importance.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "noj_book.prepare_for_ml.html",
    "href": "noj_book.prepare_for_ml.html",
    "title": "7¬† Machine learning specific functionality in tech.ml.dataset",
    "section": "",
    "text": "7.1 Categorical variables\nOne typical problem in machine learning is classification, so learning how to categorize data in different categories. Sometimes data in this format is as well called ‚Äúqualitative data‚Äù or data having discrete values.\nThese categories are often expressed in Clojure as of being of type String or keyword\nIn dataset it is the Column which has specific support for categorical data.\nCreating a column out of categorical data looks like this:\nThis creates a ‚Äúcategorical‚Äù column, which is marked as such in the column metadata.\nPrinting the var shows its ‚Äútype‚Äù as being keyword\nand printing its metadata shows that it got marked as categorical\nThe column is therefore using its metadata to store important information, and it is important to get used to look at it for the case of debugging issues.\nThe same happens, when creating a dataset which is a seq of columns",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "noj_book.prepare_for_ml.html#categorical-variables",
    "href": "noj_book.prepare_for_ml.html#categorical-variables",
    "title": "7¬† Machine learning specific functionality in tech.ml.dataset",
    "section": "",
    "text": "(require '[tech.v3.dataset.column :as col]\n         '[tech.v3.dataset :as ds])\n\n\n(def column-x (col/new-column  :x  [:a :b]))\n\n\n\n\ncolumn-x\n\n\n#tech.v3.dataset.column&lt;keyword&gt;[2]\n:x\n[:a, :b]\n\n\n\n(meta column-x)\n\n\n{:categorical? true, :name :x, :datatype :keyword, :n-elems 2}\n\n\n\n\n(def categorical-ds\n  (ds/-&gt;dataset\n   {:x [:a :b] :y [\"c\" \"d\"]}))\n\n\ncategorical-ds\n\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n:a\nc\n\n\n:b\nd\n\n\n\n\n\n(map\n meta\n (vals categorical-ds))\n\n\n({:categorical? true, :name :x, :datatype :keyword, :n-elems 2}\n {:categorical? true, :name :y, :datatype :string, :n-elems 2})\n\n\n7.1.1 Transform categorical variables to numerical space\nMost machine learning models can only work on numerical values, both for features and the target variable. So usually we need to transform categorical data into a numeric representation, so each category need to be converted to a number.\nThese numbers have often no meaning for the users, so often we need to convert back into String / keyword space later on.\nNamespace tech.v3.dataset.categorical has several functions to do so.\n\n\n7.1.2 Transform categorical column into a numerical column\n\n(require  '[tech.v3.dataset.categorical :as ds-cat])\n\nThese functions operate on a single column, but expect a dataset and a column name as input.\nWe use them to calculate a mapping from string/keyword to a numerical space (0 ‚Ä¶ x) like this\n\n(ds-cat/fit-categorical-map categorical-ds :x)\n\n\n{:lookup-table {:a 0, :b 1}, :src-column :x, :result-datatype :float64}\n\nThis maps the values in their order of occurrence in the column to 0 .. 1 This is a bit dangerous, as the mapping is decided by ‚Äúrow order‚Äù, which could change or be different on other subset of the data, like test/train splits\nSo it is preferred to be specified explicitly.\n\n(def x-mapping (ds-cat/fit-categorical-map categorical-ds :x [:a :b]))\n\n\nx-mapping\n\n\n{:lookup-table {:a 0, :b 1}, :src-column :x, :result-datatype :float64}\n\nNow we know for sure, that :a is mapped to 0 and :b is mapped to 1. Once we have a mapping, we can use it on new data and transform it into numerical values\n\n(def numerical-categorical-data\n  (ds-cat/transform-categorical-map\n   (ds/-&gt;dataset {:x [:a :b :a :b :b :b]})\n   x-mapping))\n\n\nnumerical-categorical-data\n\n\n_unnamed [6 1]:\n\n\n\n:x\n\n\n\n\n0.0\n\n\n1.0\n\n\n0.0\n\n\n1.0\n\n\n1.0\n\n\n1.0\n\n\n\n\nWe can revert it as well:\n\n(ds-cat/invert-categorical-map numerical-categorical-data x-mapping)\n\n\n_unnamed [6 1]:\n\n\n\n:x\n\n\n\n\n:a\n\n\n:b\n\n\n:a\n\n\n:b\n\n\n:b\n\n\n:b\n\n\n\n\nWe can as well ask about all mapping of a dataset:\n\n(ds-cat/dataset-&gt;categorical-maps numerical-categorical-data)\n\n\n({:lookup-table {:a 0, :b 1},\n  :src-column :x,\n  :result-datatype :float64})",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "noj_book.prepare_for_ml.html#convert-several-columns-in-one-go",
    "href": "noj_book.prepare_for_ml.html#convert-several-columns-in-one-go",
    "title": "7¬† Machine learning specific functionality in tech.ml.dataset",
    "section": "7.2 Convert several columns in one go",
    "text": "7.2 Convert several columns in one go\nThe dataset namespace has a convenience function in which several columns can be selected for conversion.\n\n(ds/categorical-&gt;number categorical-ds [:x :y])\n\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n0.0\n1.0\n\n\n1.0\n0.0\n\n\n\n\nThis works as well with filter function from namespace column-filters\n\n(require '[tech.v3.dataset.column-filters :as ds-cf])\n\nto convert all categorical columns, for example:\n\n(ds/categorical-&gt;number categorical-ds ds-cf/categorical)\n\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n0.0\n1.0\n\n\n1.0\n0.0\n\n\n\n\n\n(-&gt;\n (ds/-&gt;dataset {:x [:a :b]\n                :y [:c :d]})\n (ds/categorical-&gt;number [:x :y] [:a :b :c :d]))\n\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n0.0\n2.0\n\n\n1.0\n3.0\n\n\n\n\n\n(-&gt;\n (ds/-&gt;dataset {:x [:a :b]\n                :y [:c :d]})\n (ds/categorical-&gt;number [:x :y] [:a 0 :b 1 :c 2 :d 3]))\n\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n0.0\n4.0\n\n\n2.0\n6.0",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "noj_book.prepare_for_ml.html#warning-pitfalls-of-categorical-maps",
    "href": "noj_book.prepare_for_ml.html#warning-pitfalls-of-categorical-maps",
    "title": "7¬† Machine learning specific functionality in tech.ml.dataset",
    "section": "7.3 Warning: Pitfalls of Categorical maps",
    "text": "7.3 Warning: Pitfalls of Categorical maps\n\n7.3.1 Automatic mapping might result in surprising results\nWe need to be careful when visually inspecting columns without reverting the categorical maps.\nApplying the following map to a dataset\n\n(ds-cat/fit-categorical-map (ds/-&gt;dataset {:x [\"true\" \"false\" ]}) :x)\n\n\n{:lookup-table {\"true\" 0, \"false\" 1},\n :src-column :x,\n :result-datatype :float64}\n\nwould result in columns in which ‚Äò0‚Äô would mean ‚Äòtrue‚Äô, and ‚Äò1‚Äô would mean ‚Äòfalse‚Äô\n\n\n7.3.2 float vs int\nThe categories can get mapped to int or float\n\n(def ds-with-float-and-int-mappings\n  (-&gt;\n   (ds/-&gt;dataset {:x-float [:a :b]\n                  :x-int [:a :b]})\n   (ds/categorical-&gt;number [:x-float] [] :float64)\n   (ds/categorical-&gt;number [:x-int]   [] :int)))\n\nComparing such columns might not bring the expected result, even though the categorical maps and values look very similar\n\nds-with-float-and-int-mappings\n\n\n_unnamed [2 2]:\n\n\n\n:x-float\n:x-int\n\n\n\n\n0.0\n0\n\n\n1.0\n1\n\n\n\n\n\n(map meta\n     (vals ds-with-float-and-int-mappings))\n\n\n({:categorical? true,\n  :name :x-float,\n  :datatype :float64,\n  :n-elems 2,\n  :categorical-map\n  {:lookup-table {:a 0, :b 1},\n   :src-column :x-float,\n   :result-datatype :float64}}\n {:categorical? true,\n  :name :x-int,\n  :datatype :int,\n  :n-elems 2,\n  :categorical-map\n  {:lookup-table {:a 0, :b 1},\n   :src-column :x-int,\n   :result-datatype :int}})\n\n\n\n7.3.3 Categorical maps attached to a column change semantic value of the Column\nThe existence of categorical maps on a column, change the semantic value of the data. When categorical maps are different for two columns (for whatever reasons), it is not given that the column cell value like 0 means the same in both columns. Columns which have categorical maps should never be compared via clojure.core/= as this will ignore the categorical maps. (unless we are sure that the categorical maps in both are the same) They should be converted back to their original space and then compared. This is specially important for comparing prediction and true value in machine learning for metric calculations.\nSee the following example to illustrate this.\n\n7.3.3.1 Incorrect comparisons\nIn the following the two columns are clearly different (the opposite even)\n\n(def ds-with-different-cat-maps\n  (-&gt;\n   (ds/-&gt;dataset {:x-1 [:a :b :a :b :b :b]\n                  :x-2 [:b :a :b :a :a :a]})\n   (ds/categorical-&gt;number [:x-1 :x-2])))\n\nThe resulting columns look the same, but are not\n\n(:x-1 ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-1\n[0, 1, 0, 1, 1, 1]\n\n\n(:x-2 ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-2\n[0, 1, 0, 1, 1, 1]\n\nBy using default categorical-&gt;number we get different categorical maps, having different :lookup-tables\n\n(meta (:x-1 ds-with-different-cat-maps))\n\n\n{:categorical? true,\n :name :x-1,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:a 0, :b 1},\n  :src-column :x-1,\n  :result-datatype :float64}}\n\n\n(meta (:x-2 ds-with-different-cat-maps))\n\n\n{:categorical? true,\n :name :x-2,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:b 0, :a 1},\n  :src-column :x-2,\n  :result-datatype :float64}}\n\nso they are (wrongly) compared as equal\n\n(=\n (:x-1 ds-with-different-cat-maps)\n (:x-2 ds-with-different-cat-maps))\n\n\ntrue\n\n\n\n7.3.3.2 Correct comparison\nIn order to compare them correctly, we need to first revert the categorical mappings\n\n(def reverted-ds-with-different-cat-maps\n  (ds-cat/reverse-map-categorical-xforms ds-with-different-cat-maps))\n\n\n(:x-1 reverted-ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;keyword&gt;[6]\n:x-1\n[:a, :b, :a, :b, :b, :b]\n\n\n(:x-2 reverted-ds-with-different-cat-maps)\n\n\n#tech.v3.dataset.column&lt;keyword&gt;[6]\n:x-2\n[:b, :a, :b, :a, :a, :a]\n\nand now they compare correctly as :false\n\n(=\n (:x-1 reverted-ds-with-different-cat-maps)\n (:x-2 reverted-ds-with-different-cat-maps))\n\n\nfalse\n\nSo it should be as well avoided to transform mapped columns to other representations, which loose the mappings, like tensor or primitive arrays, or even sequences\n\n\n7.3.3.3 Use the same and fixed mapping\nThis issue can be avoided by specifying concretely the mapping to be used, as being for example {:a 0 :b 1}\n\n(def ds-with-same-cat-maps\n  (-&gt;\n   (ds/-&gt;dataset {:x-1 [:a :b :a :b :b :b]\n                  :x-2 [:b :a :b :a :a :a]})\n   (ds/categorical-&gt;number [:x-1 :x-2] [:a :b])))\n\nmapping spec can be either [:a :b] or [:a 0 :b 1]\n\n(:x-1 ds-with-same-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-1\n[0, 1, 0, 1, 1, 1]\n\n\n(:x-2 ds-with-same-cat-maps)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[6]\n:x-2\n[1, 0, 1, 0, 0, 0]\n\nwe get same categorical maps\n\n(meta (:x-1 ds-with-same-cat-maps))\n\n\n{:categorical? true,\n :name :x-1,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:a 0, :b 1},\n  :src-column :x-1,\n  :result-datatype :float64}}\n\n\n(meta (:x-2 ds-with-same-cat-maps))\n\n\n{:categorical? true,\n :name :x-2,\n :datatype :float64,\n :n-elems 6,\n :categorical-map\n {:lookup-table {:a 0, :b 1},\n  :src-column :x-2,\n  :result-datatype :float64}}\n\nso they are correctly compared as not equal\n\n(=\n (:x-1 ds-with-same-cat-maps)\n (:x-2 ds-with-same-cat-maps))\n\n\nfalse\n\nThese 3 pitfalls can be avoided by explicitly specifying the mappings, so using the 4-arity of conversion functions.\n\n(def ds-with-explicit-mapping\n  (-&gt;\n   (ds/-&gt;dataset {:x-1 [:a :b :a :b :b :b]\n                  :x-2 [:b :a :b :a :a :a]})\n   (ds/categorical-&gt;number [:x-1 :x-2] [:a :b] :int)))\n\n\nds-with-explicit-mapping\n\n\n_unnamed [6 2]:\n\n\n\n:x-1\n:x-2\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n0\n1\n\n\n1\n0\n\n\n1\n0\n\n\n1\n0\n\n\n\n\n\n(map meta (vals ds-with-explicit-mapping))\n\n\n({:categorical? true,\n  :name :x-1,\n  :datatype :int,\n  :n-elems 6,\n  :categorical-map\n  {:lookup-table {:a 0, :b 1},\n   :src-column :x-1,\n   :result-datatype :int}}\n {:categorical? true,\n  :name :x-2,\n  :datatype :int,\n  :n-elems 6,\n  :categorical-map\n  {:lookup-table {:a 0, :b 1},\n   :src-column :x-2,\n   :result-datatype :int}})\n\n\n\n\n7.3.4 one-hot-encoding\nFor some models / use cases the categorical data need to be converted in the so called one-hot format. In this every column get multiplied by the number of categories , and then each one-hot column can only have 0 and 1 values.\n\n(def one-hot-map-x (ds-cat/fit-one-hot categorical-ds :x))\n\n\n(def one-hot-map-y (ds-cat/fit-one-hot categorical-ds :y))\n\n\none-hot-map-x\n\n\n{:one-hot-table {:a :x-a, :b :x-b},\n :src-column :x,\n :result-datatype :float64}\n\n\none-hot-map-y\n\n\n{:one-hot-table {\"d\" :y-d, \"c\" :y-c},\n :src-column :y,\n :result-datatype :float64}\n\n\ncategorical-ds\n\n\n_unnamed [2 2]:\n\n\n\n:x\n:y\n\n\n\n\n:a\nc\n\n\n:b\nd\n\n\n\n\nget transformed by\n\n(def one-hot-ds\n  (-&gt; categorical-ds\n      (ds-cat/transform-one-hot one-hot-map-x)\n      (ds-cat/transform-one-hot one-hot-map-y)))\n\ninto\n\none-hot-ds\n\n\n_unnamed [2 4]:\n\n\n\n:x-a\n:x-b\n:y-d\n:y-c\n\n\n\n\n1\n0\n0\n1\n\n\n0\n1\n1\n0\n\n\n\n\nThere are similar functions to convert this format back.\n## Features and inference target in a dataset\nA dataset for supervised machine learning has always two groups of columns. They can either be the features or the inference targets. The goal of the learning is to find the relationship between the two groups and therefore be able to predict inference targets from features. Sometimes the features are called X and the targets y.\nWhen constructing a dataset\n\n(def ds\n  (ds/-&gt;dataset {:x-1 [0 1 0]\n                 :x-2 [1 0 1]\n                 :y [:a :a :b]}))\n\nwe need to mark explicitly which columns are features and which are targets in order to be able to use the dataset later for machine learning in metamorph.ml\nAs normally only one or a few columns are inference targets, we can simply mark those and the other columns are regarded as features.\n\n(require  '[tech.v3.dataset.modelling :as ds-mod])\n\n\n(def modelled-ds\n  (-&gt; ds\n      (ds-mod/set-inference-target :y)))\n\n(works as well with a seq)\nThis is marked as well in the column metadata.\n\n(-&gt; modelled-ds :y meta)\n\n\n{:categorical? true,\n :name :y,\n :datatype :keyword,\n :n-elems 3,\n :inference-target? true}\n\nThere are several functions to get information on features and inference targets:\n\n(ds-mod/feature-ecount modelled-ds)\n\n\n3\n\n\n(ds-cf/feature modelled-ds)\n\n\n_unnamed [3 2]:\n\n\n\n:x-1\n:x-2\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n0\n1\n\n\n\n\n\n(ds-cf/target modelled-ds)\n\n\n_unnamed [3 1]:\n\n\n\n:y\n\n\n\n\n:a\n\n\n:a\n\n\n:b",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "noj_book.prepare_for_ml.html#combining-categorical-transformation-and-modelling",
    "href": "noj_book.prepare_for_ml.html#combining-categorical-transformation-and-modelling",
    "title": "7¬† Machine learning specific functionality in tech.ml.dataset",
    "section": "7.4 Combining categorical transformation and modelling",
    "text": "7.4 Combining categorical transformation and modelling\nVery often we need to do transform and model for doing classification and combine the -&gt;numeric transformation of categorical vars and the marking of inference targets.\n\n(def ds-ready-for-train\n  (-&gt;\n   {:x-1 [0 1 0]\n    :x-2 [1 0 1]\n    :cat  [:a :b :c]\n    :y [:a :a :b]}\n\n   (ds/-&gt;dataset)\n   (ds/categorical-&gt;number [:y])\n   (ds/categorical-&gt;one-hot [:cat])\n   (ds-mod/set-inference-target [:y])))\n\n\nds-ready-for-train\n\n\n_unnamed [3 6]:\n\n\n\n:x-1\n:x-2\n:y\n:cat-c\n:cat-a\n:cat-b\n\n\n\n\n0\n1\n0.0\n0\n1\n0\n\n\n1\n0\n0.0\n0\n0\n1\n\n\n0\n1\n1.0\n1\n0\n0\n\n\n\n\nSuch a dataset is ready for training as it only contains numerical variables which have the categorical maps in place for easy converting back, if needed. The inference target is marked as well, as we can see in the meta data:\n\n(map meta (vals ds-ready-for-train))\n\n\n({:name :x-1, :datatype :int64, :n-elems 3}\n {:name :x-2, :datatype :int64, :n-elems 3}\n {:categorical? true,\n  :name :y,\n  :datatype :float64,\n  :n-elems 3,\n  :categorical-map\n  {:lookup-table {:a 0, :b 1},\n   :src-column :y,\n   :result-datatype :float64},\n  :inference-target? true}\n {:categorical? true,\n  :name :cat-c,\n  :datatype :int8,\n  :n-elems 3,\n  :one-hot-map\n  {:one-hot-table {:c :cat-c, :a :cat-a, :b :cat-b},\n   :src-column :cat,\n   :result-datatype :float64}}\n {:categorical? true,\n  :name :cat-a,\n  :datatype :int8,\n  :n-elems 3,\n  :one-hot-map\n  {:one-hot-table {:c :cat-c, :a :cat-a, :b :cat-b},\n   :src-column :cat,\n   :result-datatype :float64}}\n {:categorical? true,\n  :name :cat-b,\n  :datatype :int8,\n  :n-elems 3,\n  :one-hot-map\n  {:one-hot-table {:c :cat-c, :a :cat-a, :b :cat-b},\n   :src-column :cat,\n   :result-datatype :float64}})\n\nMost models in the metamorph.ml ecosystem can work with data in this format.\nSide remark: If needed, data could as well be easily transformed into a tensor. Most models do this internally anyway (often to primitive arrays)\n\n(require 'tech.v3.dataset.tensor)\n\n\n(def ds-tensor\n  (tech.v3.dataset.tensor/dataset-&gt;tensor ds-ready-for-train))\n\n\nds-tensor\n\n\n#tech.v3.tensor&lt;float64&gt;[3 6]\n[[0.000 1.000 0.000 0.000 1.000 0.000]\n [1.000 0.000 0.000 0.000 0.000 1.000]\n [0.000 1.000 1.000 1.000 0.000 0.000]]\n\nor we can do so, if needed, but this looses the notation of features / inference target\n\n(tech.v3.tensor/-&gt;jvm ds-tensor)\n\n\n[[0.0 1.0 0.0 0.0 1.0 0.0]\n [1.0 0.0 0.0 0.0 0.0 1.0]\n [0.0 1.0 1.0 1.0 0.0 0.0]]\n\n\nsource: notebooks/noj_book/prepare_for_ml.clj",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Machine learning specific functionality in `tech.ml.dataset`</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html",
    "href": "noj_book.automl.html",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "",
    "text": "8.1 The metamorph pipeline abstraction\nWhen doing automl, it is very useful to be able to manage the steps of a machine learning pipeline (including data transformations and modeling) as a unified function that can be freely moved around. This cannot work with a threading macro, as this executes immediate.\nThe Clojure way to do this, is function composing and higher level functions\n(The following is a very low level explanation of metamorph, as a metamorph.ml user we do not use this low-level functions , see next chapter)\nWhile before we saw how to use the pair of train and predict to perform machine learning, AutoML requires us to use an other abstraction, in order to encapsulate both train and predict in single function.(or other any operation)\nWe will use the concept of a ‚Äúmetamorph pipeline‚Äù, which is a sequence of specific functions, and each function can behaves differently, depending on the ‚Äúmode‚Äù in which the pipelines get run. It can run either in mode :fit or in mode :transform, and the functions of the pipeline can (but don‚Äôt need to) do different things depend on the mode\nSpecifically we have a function called metamorph.ml/model which will do train in mode :fit and predict in mode :transform\nThe names :fit and :transform come from the fact that functions could do other things then train and predict, so :fit and :transform represent a more general concept then train/predict\nWe will use the ready-for-modeling data from basic-ml tutorial,\nso lets create splits of the data first.\nIn its foundation a metamorph pipeline is a sequential composition of functions, which all take a map as only parameter, the so called context, and they return an other context, changed by the functions. The composed function , hence the pipeline overall, has this same property. Any other function parameters are closed over on function creation. The following creates such a composed function out of other metamorph compliant operations. The overall result of the pipeline function, is the result of the last operation. (in this case we have only ‚Äò1‚Äô operation)\nIn nearly all cases, the last pipeline operation is ml/model . But this is not absolutely required.\nas we see, this is a function itself\nThis function is metamorph compliant, so it takes a map (my-pipeline {}) and returns a map.\nBut this map cannot be ‚Äúarbitrary‚Äù, it need to adhere to the metamorph conventions.\nThe following trains a model, because the ml/model function does this when called with :mode :fit. And it is the only operation in the pipeline, so the pipeline does one thing, it trains a model\nThe ctx contains lots of information, so I only show its top level keys\nThis context map has the ‚Äúdata‚Äù, the ‚Äúmode‚Äù and an UUID for each operation (we had only one in this pipeline)\nThe model function has closed over the id, so is knows ‚Äúhis id‚Äù, so in the transform mode it can get the data created at :fit. So the model function can ‚Äúsend‚Äù data to itself from :fit to :transform, the trained model.\nSo this will do the predict on new data\nFor the dummy-model we do not see a trained-model, but it ‚Äúcommunicates‚Äù the majority class from the train data to use it for prediction. So the dummy-model has ‚Äòlearned‚Äô the majority class from its training data.\nSo we can get prediction result out of the ctx:\nThis works as long as all operations of the pipeline follow the metamorph convention (we can create such compliant functions, out of normal dataset-&gt;dataset functions, as we will see)\nmy-pipeline represents therefore a not yet executed model training / prediction flow. It can be freely moved around and applied to datasets when needed.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html#the-metamorph-pipeline-abstraction",
    "href": "noj_book.automl.html#the-metamorph-pipeline-abstraction",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "",
    "text": "(require '[scicloj.metamorph.ml :as ml]\n         '[scicloj.metamorph.core :as mm]\n         '[tablecloth.api :as tc])\n\n\n\n(def titanic ml-basic/numeric-titanic-data)\n\n\n\n(def splits (first (tc/split-&gt;seq titanic)))\n\n\n(def train-ds (:train splits))\n\n\n(def test-ds (:test splits))\n\n\n\n\n(def my-pipeline\n  (mm/pipeline\n   (ml/model {:model-type :metamorph.ml/dummy-classifier})))\n\n\n\nmy-pipeline\n\n\n#object[clojure.core$partial$fn__5927 0x50168b34 \"clojure.core$partial$fn__5927@50168b34\"]\n\n\n\n\n\n(def ctx-after-train\n  (my-pipeline {:metamorph/data train-ds\n                :metamorph/mode :fit}))\n\n\nctx-after-train\n\n{\n\n\n\n\n\n\n\n\n:metamorph/data\n\n\n\nGroup: 0 [711 4]:\n\n\n\n:sex\n:pclass\n:embarked\n:survived\n\n\n\n\n1.0\n3.0\n1.0\n1.0\n\n\n0.0\n1.0\n0.0\n0.0\n\n\n1.0\n1.0\n0.0\n1.0\n\n\n0.0\n2.0\n2.0\n0.0\n\n\n1.0\n3.0\n0.0\n1.0\n\n\n0.0\n2.0\n0.0\n0.0\n\n\n0.0\n3.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n1.0\n1.0\n2.0\n1.0\n\n\n...\n...\n...\n...\n\n\n0.0\n3.0\n2.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n1.0\n0.0\n1.0\n\n\n0.0\n3.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n2.0\n0.0\n\n\n1.0\n3.0\n2.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n1.0\n2.0\n1.0\n\n\n\n\n\n\n\n\n:metamorph/mode :fit#uuid \"5b0f9ee6-0c7a-4577-8692-414cc8578d35\" {:model-data {:majority-class 0.0, :distinct-labels (1.0 0.0)}, :options {:model-type :metamorph.ml/dummy-classifier}, :id #uuid \"5f7b3c1f-cce0-4300-b3d6-b3b0f29952d0\", :feature-columns [:sex :pclass :embarked], :target-columns [:survived], :target-categorical-maps {:survived #tech.v3.dataset.categorical.CategoricalMap{:lookup-table {\"no\" 0, \"yes\" 1}, :src-column :survived, :result-datatype :float64}}, :scicloj.metamorph.ml/unsupervised? nil}}\n\n\n(keys ctx-after-train)\n\n\n(:metamorph/data\n :metamorph/mode\n #uuid \"5b0f9ee6-0c7a-4577-8692-414cc8578d35\")\n\n\n\n(vals ctx-after-train)\n\n(Group: 0 [711 4]:\n\n\n\n:sex\n:pclass\n:embarked\n:survived\n\n\n\n\n1.0\n3.0\n1.0\n1.0\n\n\n0.0\n1.0\n0.0\n0.0\n\n\n1.0\n1.0\n0.0\n1.0\n\n\n0.0\n2.0\n2.0\n0.0\n\n\n1.0\n3.0\n0.0\n1.0\n\n\n0.0\n2.0\n0.0\n0.0\n\n\n0.0\n3.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n1.0\n1.0\n2.0\n1.0\n\n\n...\n...\n...\n...\n\n\n0.0\n3.0\n2.0\n0.0\n\n\n1.0\n2.0\n0.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n1.0\n0.0\n1.0\n\n\n0.0\n3.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n2.0\n0.0\n\n\n1.0\n3.0\n2.0\n1.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n3.0\n0.0\n0.0\n\n\n0.0\n1.0\n2.0\n1.0\n\n\n\n:fit\n{:model-data {:majority-class 0.0, :distinct-labels (1.0 0.0)},\n :options {:model-type :metamorph.ml/dummy-classifier},\n :id #uuid \"5f7b3c1f-cce0-4300-b3d6-b3b0f29952d0\",\n :feature-columns [:sex :pclass :embarked],\n :target-columns [:survived],\n :target-categorical-maps\n {:survived\n  {:lookup-table {\"no\" 0, \"yes\" 1},\n   :src-column :survived,\n   :result-datatype :float64}},\n :scicloj.metamorph.ml/unsupervised? nil}\n)\n\n\n\n(def ctx-after-predict\n  (my-pipeline (assoc ctx-after-train\n                      :metamorph/mode :transform\n                      :metamorph/data test-ds)))\n\n\n(keys ctx-after-predict)\n\n\n(:metamorph/data\n :metamorph/mode\n #uuid \"5b0f9ee6-0c7a-4577-8692-414cc8578d35\")\n\n\n\n\n(-&gt; ctx-after-predict :metamorph/data :survived)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[178]\n:survived\n[0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000...]",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html#use-metamorph-pipelines-to-do-model-training-with-higher-level-api",
    "href": "noj_book.automl.html#use-metamorph-pipelines-to-do-model-training-with-higher-level-api",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "8.2 Use metamorph pipelines to do model training with higher level API",
    "text": "8.2 Use metamorph pipelines to do model training with higher level API\nAs user of metamorph.ml we do not need to deal with this low-level details of how metamorph works, we have convenience functions which hide this.\nThe following code will do the same as train, but return a context object, which contains the trained model, so it will execute the pipeline, and not only create it.\nIt uses a convenience function mm/fit which generates compliant context maps internally and executes the pipeline as well.\nThe ctx acts a collector of everything ‚Äúlearned‚Äù during :fit, mainly the trained model, but it could be as well other information learned from the data during :fit and to be applied at :transform .\n\n(def train-ctx\n  (mm/fit titanic\n          (ml/model {:model-type :metamorph.ml/dummy-classifier})))\n\n(The dummy-classifier model does not have a lot of state, so there is little to see)\n\n(keys train-ctx)\n\n\n(:metamorph/data\n :metamorph/mode\n #uuid \"f4c8fb74-7e78-4b66-8e21-e3918a49823e\")\n\nTo show the power of pipelines, I start with doing the simplest possible pipeline, and expand then on it.\nWe can already chain train and test with usual functions:\n\n(-&gt;&gt;\n (ml/train train-ds {:model-type :metamorph.ml/dummy-classifier})\n (ml/predict test-ds)\n :survived)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[178]\n:survived\n[0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000...]\n\nthe same with pipelines\n\n(def pipeline\n  (mm/pipeline (ml/model {:model-type :metamorph.ml/dummy-classifier})))\n\n\n(-&gt;&gt;\n (mm/fit-pipe train-ds pipeline)\n (mm/transform-pipe test-ds pipeline)\n :metamorph/data :survived)\n\n\n#tech.v3.dataset.column&lt;float64&gt;[178]\n:survived\n[0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000...]",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html#create-metamorph-compliant-functions",
    "href": "noj_book.automl.html#create-metamorph-compliant-functions",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "8.3 Create metamorph compliant functions",
    "text": "8.3 Create metamorph compliant functions\nAs said before, a metamorph pipeline is composed of metamorph compliant functions / operations, which take as input and output the ctx. There are three ways to create those.\nThe following three expressions create the same metamorph compliant function\n\nimplementing a metamorph compliant function directly via anonymous function\n\n\n(def ops-1\n  (fn [ctx]\n    (assoc ctx :metamorph/data\n           (tc/drop-columns (:metamorph/data ctx) [:embarked]))))\n\n\nusing mm/lift which does the same as 1.\n\n\n(def ops-2 (mm/lift tc/drop-columns [:embarked]))\n\n\nusing a name-space containing lifted functions\n\n\n(require '[tablecloth.pipeline])\n\n\n(def ops-3 (tablecloth.pipeline/drop-columns [:embarked]))\n\nAll three create the same pipeline op and can be used to make a pipeline\n\n(mm/pipeline ops-1)\n\n\n#object[clojure.core$partial$fn__5927 0x31741039 \"clojure.core$partial$fn__5927@31741039\"]\n\n\n(mm/pipeline ops-2)\n\n\n#object[clojure.core$partial$fn__5927 0x205783fb \"clojure.core$partial$fn__5927@205783fb\"]\n\n\n(mm/pipeline ops-3)\n\n\n#object[clojure.core$partial$fn__5927 0x600819de \"clojure.core$partial$fn__5927@600819de\"]\n\nAll three can be called as function taking a dataset iwrapped in a ctx\nPipeline as data is as well supported\n\n(def op-spec [[ml/model {:model-type :metamorph.ml/dummy-classifier}]])\n\n\n(mm/-&gt;pipeline op-spec)\n\n\n#object[clojure.core$partial$fn__5927 0x46c25499 \"clojure.core$partial$fn__5927@46c25499\"]\n\nCreating these functions does not yet execute anything, they are functions which can be executed against a context as part of a metamorph pipeline. Executions are triggered like this:\n\n(ops-1 {:metamorph/data titanic})\n\n{\n\n\n\n\n\n\n\n\n:metamorph/data\n\n\n\n_unnamed [889 3]:\n\n\n\n:sex\n:pclass\n:survived\n\n\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n1.0\n1.0\n\n\n1.0\n3.0\n1.0\n\n\n1.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n0.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n1.0\n\n\n1.0\n2.0\n1.0\n\n\n...\n...\n...\n\n\n1.0\n2.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n2.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n2.0\n0.0\n\n\n1.0\n1.0\n1.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n\n\n\n\n\n\n}\n\n(ops-2 {:metamorph/data titanic})\n\n{\n\n\n\n\n\n\n\n\n:metamorph/data\n\n\n\n_unnamed [889 3]:\n\n\n\n:sex\n:pclass\n:survived\n\n\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n1.0\n1.0\n\n\n1.0\n3.0\n1.0\n\n\n1.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n0.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n1.0\n\n\n1.0\n2.0\n1.0\n\n\n...\n...\n...\n\n\n1.0\n2.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n2.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n2.0\n0.0\n\n\n1.0\n1.0\n1.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n\n\n\n\n\n\n}\n\n(ops-3 {:metamorph/data titanic})\n\n{\n\n\n\n\n\n\n\n\n:metamorph/data\n\n\n\n_unnamed [889 3]:\n\n\n\n:sex\n:pclass\n:survived\n\n\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n1.0\n1.0\n\n\n1.0\n3.0\n1.0\n\n\n1.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n0.0\n1.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n1.0\n\n\n1.0\n2.0\n1.0\n\n\n...\n...\n...\n\n\n1.0\n2.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n2.0\n0.0\n\n\n0.0\n3.0\n0.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n2.0\n0.0\n\n\n1.0\n1.0\n1.0\n\n\n1.0\n3.0\n0.0\n\n\n0.0\n1.0\n1.0\n\n\n0.0\n3.0\n0.0\n\n\n\n\n\n\n\n\n}\nThe mm/lift function transforms any dataset-&gt;dataset function into a ctx-&gt;ctx function, while using the metamorph convention, as required for metamorph pipeline operations\nFor convenience tablecloth contains a ns where all dataset-&gt;dataset functions are lifted into ctx-&gt;ctx operations, so can be added to pipelines directly without using lift.\nSo a metamorph pipeline can encapsulate arbitrary transformation of a dataset in the 2 modes. They can be ‚Äústateless‚Äù (only chaining the dataset, such as drop-columns) or ‚Äústate-full‚Äù, so they store data in the ctx during :fit and can use it in :transform. In the pipeline above, the trained model is stored in this way.\nThis state is not stored globally, but inside the pipeline so this makes pipeline execution ‚Äúisolated‚Äù.\nSo now we can add more operations to the pipeline, and nothing else changes, for example drop columns.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html#automatic-ml-with-metamorph.ml",
    "href": "noj_book.automl.html#automatic-ml-with-metamorph.ml",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "8.4 Automatic ML with metamorph.ml",
    "text": "8.4 Automatic ML with metamorph.ml\nThe AutoML support in metamorph.ml consists now in the possibility to create an arbitrary number of different pipelines and have them run against arbitrary test/train data splits and it automatically chooses the best model evaluated by by a certain metric.\nhelper for later\n\n(defn make-results-ds [evaluation-results]\n  (-&gt;&gt; evaluation-results\n       flatten\n       (map #(hash-map :options (-&gt; % :test-transform :ctx :model :options)\n                       :used-features (-&gt; % :fit-ctx :used-features)\n                       :mean-accuracy (-&gt; % :test-transform :mean)))\n       tc/dataset))\n\n\n(require '[scicloj.metamorph.ml :as ml]\n         '[scicloj.metamorph.ml.loss :as loss]\n         '[scicloj.metamorph.core :as mm]\n         '[scicloj.ml.tribuo]\n         '[scicloj.ml.xgboost]\n         '[scicloj.sklearn-clj.ml])",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html#finding-the-best-model-automatically",
    "href": "noj_book.automl.html#finding-the-best-model-automatically",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "8.5 Finding the best model automatically",
    "text": "8.5 Finding the best model automatically\nThe advantage of the pipelines is even more visible, if we want to have configurable pipelines, and do a grid search to find optimal settings.\nthe following will find the best model across:\n\n4 different model classes\n6 different selections of used features\nk-cross validate this with different test / train splits\n\n\n(defn make-pipe-fn [model-spec features]\n  (mm/pipeline\n   ;; store the used features in ctx, so we can retrieve them at the end\n   (fn [ctx]\n     (assoc ctx :used-features features))\n   (mm/lift tc/select-columns (conj features :survived))\n   {:metamorph/id :model} (ml/model model-spec)))\n\nCreate a 5-K cross validation split of the data:\n\n(def titanic-k-fold (tc/split-&gt;seq ml-basic/numeric-titanic-data :kfold {:seed 12345}))\n\n\n(-&gt; titanic-k-fold count)\n\n\n5\n\nThe list of the model types we want to try:\n\n(def models [{ :model-type :xgboost/classification\n               :round 10}\n             {:model-type :sklearn.classification/decision-tree-classifier}\n             {:model-type :sklearn.classification/logistic-regression}\n             {:model-type :sklearn.classification/random-forest-classifier}\n             {:model-type :metamorph.ml/dummy-classifier}\n             {:model-type :scicloj.ml.tribuo/classification\n              :tribuo-components [{:name \"logistic\"\n                                   :type \"org.tribuo.classification.sgd.linear.LinearSGDTrainer\"}]\n              :tribuo-trainer-name \"logistic\"}\n             {:model-type :scicloj.ml.tribuo/classification\n              :tribuo-components [{:name \"random-forest\"\n                                   :type \"org.tribuo.classification.dtree.CARTClassificationTrainer\"\n                                   :properties {:maxDepth \"8\"\n                                                :useRandomSplitPoints \"false\"\n                                                :fractionFeaturesInSplit \"0.5\"}}]\n              :tribuo-trainer-name \"random-forest\"}])\n\nThis uses models from Smile and Tribuo, but could be any metamorph.ml compliant model ( library sklearn-clj wraps all python sklearn models, for example)\nThe list of feature combinations to try for each model:\n\n(def feature-combinations\n  [[:sex :pclass :embarked]\n   [:sex]\n   [:pclass :embarked]\n   [:embarked]\n   [:sex :embarked]\n   [:sex :pclass]])\n\ngenerate 24 pipeline functions:\n\n(def pipe-fns\n  (for [model models\n        feature-combination feature-combinations]\n    (make-pipe-fn model feature-combination)))\n\n\n(count pipe-fns)\n\n\n42\n\nExecute all pipelines for all splits in the cross-validations and return best model by classification-accuracy\n\n(def evaluation-results\n  (ml/evaluate-pipelines\n   pipe-fns\n   titanic-k-fold\n   loss/classification-accuracy\n   :accuracy))\n\nBy default it returns the best mode only\n\n(make-results-ds evaluation-results)\n\n\n_unnamed [1 3]:\n\n\n\n\n\n\n\n\n:used-features\n:mean-accuracy\n:options\n\n\n\n\n[:sex :pclass :embarked]\n0.81107726\n{:model-type :scicloj.ml.tribuo/classification,\n\n\n\n\n:tribuo-components\n\n\n\n\n[{:name random-forest,\n\n\n\n\n:type org.tribuo.classification.dtree.CARTClassificationTrainer,\n\n\n\n\n:properties\n\n\n\n\n{:maxDepth 8,\n\n\n\n\n:useRandomSplitPoints false,\n\n\n\n\n:fractionFeaturesInSplit 0.5}}],\n\n\n\n\n:tribuo-trainer-name random-forest}\n\n\n\n\nThe key observation is here, that the metamorph pipelines allow to not only grid-search over the model hyper-parameters, but as well over arbitrary pipeline variations, like which features to include. Both get handled in the same way.\nWe can get all results as well:\n\n(def evaluation-results-all\n  (ml/evaluate-pipelines\n   pipe-fns\n   titanic-k-fold\n   loss/classification-accuracy\n   :accuracy\n   {:map-fn :map\n    :return-best-crossvalidation-only false\n    :return-best-pipeline-only false}))\n\nIn total it creates and evaluates 4 models * 6 feature configurations * 5 CV = 120 models\n\n(-&gt;  evaluation-results-all flatten count)\n\n\n210\n\nWe can find the best as well by hand, it‚Äôs the first from the list, when sorted by accuracy.\n\n(-&gt; (make-results-ds evaluation-results-all)\n    (tc/unique-by)\n    (tc/order-by [:mean-accuracy] :desc)\n    (tc/head 20)\n    (kind/table))\n\n\n\n\n\n\n\n\n\n\n\nused-features\nmean-accuracy\noptions\n\n\n\n\n\n[:sex :pclass :embarked]\n\n0.8110772551260077\n\n{:model-type :sklearn.classification/random-forest-classifier}\n\n\n\n\n[:sex :pclass :embarked]\n\n0.8110772551260077\n\n{:model-type :sklearn.classification/decision-tree-classifier}\n\n\n\n\n[:sex :pclass :embarked]\n\n0.8110772551260077\n\n{:model-type :xgboost/classification, :round 10}\n\n\n\n\n[:sex :pclass :embarked]\n\n0.8110772551260077\n\n{:model-type :scicloj.ml.tribuo/classification,\n :tribuo-components\n [{:name \"random-forest\",\n   :type \"org.tribuo.classification.dtree.CARTClassificationTrainer\",\n   :properties\n   {:maxDepth \"8\",\n    :useRandomSplitPoints \"false\",\n    :fractionFeaturesInSplit \"0.5\"}}],\n :tribuo-trainer-name \"random-forest\"}\n\n\n\n\n[:sex :pclass]\n\n0.7863327620135847\n\n{:model-type :scicloj.ml.tribuo/classification,\n :tribuo-components\n [{:name \"logistic\",\n   :type \"org.tribuo.classification.sgd.linear.LinearSGDTrainer\"}],\n :tribuo-trainer-name \"logistic\"}\n\n\n\n\n[:sex :embarked]\n\n0.7863327620135847\n\n{:model-type :scicloj.ml.tribuo/classification,\n :tribuo-components\n [{:name \"logistic\",\n   :type \"org.tribuo.classification.sgd.linear.LinearSGDTrainer\"}],\n :tribuo-trainer-name \"logistic\"}\n\n\n\n\n[:sex]\n\n0.7863327620135847\n\n{:model-type :scicloj.ml.tribuo/classification,\n :tribuo-components\n [{:name \"logistic\",\n   :type \"org.tribuo.classification.sgd.linear.LinearSGDTrainer\"}],\n :tribuo-trainer-name \"logistic\"}\n\n\n\n\n[:sex :embarked]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/random-forest-classifier}\n\n\n\n\n[:sex]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/random-forest-classifier}\n\n\n\n\n[:sex :pclass]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/logistic-regression}\n\n\n\n\n[:sex :embarked]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/logistic-regression}\n\n\n\n\n[:sex]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/logistic-regression}\n\n\n\n\n[:sex :embarked]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/decision-tree-classifier}\n\n\n\n\n[:sex]\n\n0.7863327620135847\n\n{:model-type :xgboost/classification, :round 10}\n\n\n\n\n[:sex :embarked]\n\n0.7863327620135847\n\n{:model-type :xgboost/classification, :round 10}\n\n\n\n\n[:sex]\n\n0.7863327620135847\n\n{:model-type :sklearn.classification/decision-tree-classifier}\n\n\n\n\n[:sex]\n\n0.7863327620135847\n\n{:model-type :scicloj.ml.tribuo/classification,\n :tribuo-components\n [{:name \"random-forest\",\n   :type \"org.tribuo.classification.dtree.CARTClassificationTrainer\",\n   :properties\n   {:maxDepth \"8\",\n    :useRandomSplitPoints \"false\",\n    :fractionFeaturesInSplit \"0.5\"}}],\n :tribuo-trainer-name \"random-forest\"}\n\n\n\n\n[:sex :pclass :embarked]\n\n0.7852091665079668\n\n{:model-type :scicloj.ml.tribuo/classification,\n :tribuo-components\n [{:name \"logistic\",\n   :type \"org.tribuo.classification.sgd.linear.LinearSGDTrainer\"}],\n :tribuo-trainer-name \"logistic\"}\n\n\n\n\n[:sex :pclass :embarked]\n\n0.7750777629657843\n\n{:model-type :sklearn.classification/logistic-regression}\n\n\n\n\n[:sex :pclass]\n\n0.773973211451787\n\n{:model-type :sklearn.classification/random-forest-classifier}",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.automl.html#best-practices-for-data-transformation-steps-in-or-outside-pipeline",
    "href": "noj_book.automl.html#best-practices-for-data-transformation-steps-in-or-outside-pipeline",
    "title": "8¬† AutoML using metamorph pipelines",
    "section": "8.6 Best practices for data transformation steps in or outside pipeline",
    "text": "8.6 Best practices for data transformation steps in or outside pipeline\n\n(require '[scicloj.metamorph.ml.toydata :as data]\n         '[tech.v3.dataset.modelling :as ds-mod]\n         '[tech.v3.dataset.categorical :as ds-cat]\n         '[tech.v3.dataset :as ds])\n\nWe have seen that we have two ways to transform the input data, outside the pipeline and inside the pipeline.\nThese are the total steps from raw data to ‚Äúinto the model‚Äù for the titanic use case.\n\nraw data\n\n\n(def titanic\n  (:train\n   (data/titanic-ds-split)))\n\n\nfirst transformation, no metamorph pipeline\n\n\n(def relevant-titanic-data\n  (-&gt; titanic\n      (tc/select-columns (conj ml-basic/categorical-feature-columns :survived))\n      (tc/drop-missing)\n      (ds/categorical-&gt;number [:sex :pclass :embarked] [0 1 2 \"male\" \"female\" \"S\" \"Q\" \"C\"] :float64)\n      (ds/categorical-&gt;number [:survived] [0 1] :float64)\n      (ds-mod/set-inference-target :survived)))\n\n\ntransform via pipelines\n\n\n(defn make-pipe-fn [model-type features]\n  (mm/pipeline\n   ;; store the used features in ctx, so we can retrieve them at the end\n   (fn [ctx]\n     (assoc ctx :used-features features))\n   (mm/lift tc/select-columns (conj features :survived))\n   {:metamorph/id :model} (ml/model {:model-type model-type})))\n\nWhile it would be technically possible to move all steps from the ‚Äúfirst transformation‚Äù into the pipeline, by just using the ‚Äúlifted‚Äù form of the transformations, I would not do so, even though this should give the same result.\nI think it is better to separate the steps which are ‚Äúfixed‚Äù, from the steps which are parameterized, so for which we want to find the best values by ‚Äútrying out‚Äù.\nIn my view there are two reasons for this: 1. Debugging: It is harder to debug a pipeline and see the results of steps. We have one macro helping in this: mm/def-ctx 2. Performance: The pipeline is executed lots of times, for every split / variant of the pipeline. It should be faster to do things only once, before the pipeline\n\nsource: notebooks/noj_book/automl.clj",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>AutoML using metamorph pipelines</span>"
    ]
  },
  {
    "objectID": "noj_book.interactions_ols.html",
    "href": "noj_book.interactions_ols.html",
    "title": "9¬† Ordinary least squares with interactions",
    "section": "",
    "text": "9.1 Additive model\nFirst we build an additive model, which model equation is \\[sales = b0 + b1 * youtube + b2 * facebook\\]\nWe evaluate it,\nand print the resulting model: (note that the :sales term means the intercept b0)\n(note that )\nWe have the following metrics:\n\\(RMSE\\)\n\\(R^2\\)",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Ordinary least squares with interactions</span>"
    ]
  },
  {
    "objectID": "noj_book.interactions_ols.html#additive-model",
    "href": "noj_book.interactions_ols.html#additive-model",
    "title": "9¬† Ordinary least squares with interactions",
    "section": "",
    "text": "(def linear-model-config {:model-type :fastmath/ols})\n\n\n(def additive-pipeline\n  (mm/pipeline\n   {:metamorph/id :model}\n   (ml/model linear-model-config)))\n\n\n\n(def evaluations\n  (ml/evaluate-pipelines\n   [additive-pipeline]\n   (tc/split-&gt;seq preprocessed-data\n                  :holdout\n                  {:seed 112723})\n   loss/rmse\n   :loss\n   {:other-metrices [{:name :r2\n                      :metric-fn fmstats/r2-determination}]}))\n\n\n\n\n(-&gt; evaluations flatten first :fit-ctx :model ml/tidy)\n\n\n_unnamed [3 5]:\n\n\n\n:term\n:statistic\n:estimate\n:p.value\n:std.error\n\n\n\n\n:sales\n6.93059345\n3.23892397\n1.75340853E-10\n0.46733718\n\n\n:youtube\n26.78112104\n0.04746972\n0.00000000E+00\n0.00177251\n\n\n:facebook\n17.44850145\n0.18475974\n0.00000000E+00\n0.01058886\n\n\n\n\n\n\n\n(-&gt; evaluations flatten first :test-transform :metric)\n\n\n1.772159024927988\n\n\n\n(-&gt; evaluations flatten first :test-transform :other-metrices first :metric)\n\n\n0.9094193687523886",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Ordinary least squares with interactions</span>"
    ]
  },
  {
    "objectID": "noj_book.interactions_ols.html#interaction-effects",
    "href": "noj_book.interactions_ols.html#interaction-effects",
    "title": "9¬† Ordinary least squares with interactions",
    "section": "9.2 Interaction effects",
    "text": "9.2 Interaction effects\nNow we add interaction effects to it, resulting in this model equation: \\[sales = b0 + b1 * youtube + b2 * facebook + b3 * (youtube * facebook)\\]\n\n(def pipe-interaction\n  (mm/pipeline\n   (tcpipe/add-column :youtube*facebook (fn [ds] (tcc/* (ds :youtube) (ds :facebook))))\n   {:metamorph/id :model} (ml/model linear-model-config)))\n\nAgain we evaluate the model,\n\n(def evaluations\n  (ml/evaluate-pipelines\n   [pipe-interaction]\n   (tc/split-&gt;seq preprocessed-data\n                  :holdout\n                  {:seed 112723})\n   loss/rmse\n   :loss\n   {:other-metrices [{:name :r2\n                      :metric-fn fmstats/r2-determination}]}))\n\nand print it and the performance metrics:\n\n(-&gt; evaluations flatten first :fit-ctx :model ml/tidy)\n\n\n_unnamed [4 5]:\n\n\n\n\n\n\n\n\n\n\n:term\n:statistic\n:estimate\n:p.value\n:std.error\n\n\n\n\n:sales\n20.25471327\n8.16387196\n0.00000000E+00\n0.40306036\n\n\n:youtube\n9.28964322\n0.01881844\n4.44089210E-16\n0.00202574\n\n\n:facebook\n1.84214022\n0.02152468\n6.77510166E-02\n0.01168460\n\n\n:youtube*facebook\n16.34505330\n0.00093206\n0.00000000E+00\n0.00005702\n\n\n\n\nAs the multiplcation of youtube*facebook is as well statistically relevant, it suggests that there is indeed an interaction between these 2 predictor variables youtube and facebook.\n\\(RMSE\\)\n\n(-&gt; evaluations flatten first :test-transform :metric)\n\n\n0.933077510748531\n\n\\(R^2\\)\n\n(-&gt; evaluations flatten first :test-transform :other-metrices first :metric)\n\n\n0.9747551116991899\n\n\\(RMSE\\) and \\(R^2\\) of the intercation model are sligtly better.\nThese results suggest that the model with the interaction term is better than the model that contains only main effects. So, for this specific data, we should go for the model with the interaction model.\n\nsource: notebooks/noj_book/interactions_ols.clj",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Ordinary least squares with interactions</span>"
    ]
  },
  {
    "objectID": "noj_book.visualizing_correlation_matrices.html",
    "href": "noj_book.visualizing_correlation_matrices.html",
    "title": "10¬† Visualizing correlation matrices (experimental üõ†) - DRAFT",
    "section": "",
    "text": "10.1 Auxiliary functions\nRounding numbers:\nFor example (see RoundingMode)",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Visualizing correlation matrices (experimental üõ†) - DRAFT</span>"
    ]
  },
  {
    "objectID": "noj_book.visualizing_correlation_matrices.html#auxiliary-functions",
    "href": "noj_book.visualizing_correlation_matrices.html#auxiliary-functions",
    "title": "10¬† Visualizing correlation matrices (experimental üõ†) - DRAFT",
    "section": "",
    "text": "(defn round\n  [n scale rm]\n  (.setScale ^java.math.BigDecimal (bigdec n)\n             (int scale)\n             ^RoundingMode (if (instance? java.math.RoundingMode rm)\n                             rm\n                             (java.math.RoundingMode/valueOf\n                              (str (if (ident? rm) (symbol rm) rm))))))\n\n\n\n(round (/ 2.0 3) 2 :DOWN)\n\n\n0.66M\n\n\n(round (/ 2.0 3) 2 :UP)\n\n\n0.67M\n\n\n(round (/ 2.0 3) 2 :HALF_EVEN)\n\n\n0.67M",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Visualizing correlation matrices (experimental üõ†) - DRAFT</span>"
    ]
  },
  {
    "objectID": "noj_book.visualizing_correlation_matrices.html#computing-a-correlation-matrix-and-representing-it-as-a-dataset",
    "href": "noj_book.visualizing_correlation_matrices.html#computing-a-correlation-matrix-and-representing-it-as-a-dataset",
    "title": "10¬† Visualizing correlation matrices (experimental üõ†) - DRAFT",
    "section": "10.2 Computing a correlation matrix and representing it as a dataset:",
    "text": "10.2 Computing a correlation matrix and representing it as a dataset:\n\n(defn correlations-dataset [data columns-to-use]\n  (let [matrix (-&gt;&gt; columns-to-use\n                    (mapv #(get data %))\n                    fastmath.stats/correlation-matrix)]\n    (-&gt;&gt; matrix\n         (map-indexed\n          (fn [i row]\n            (let [coli (columns-to-use i)]\n              (-&gt;&gt; row\n                   (map-indexed\n                    (fn [j corr]\n                      (let [colj (columns-to-use j)]\n                        {:i i\n                         :j j\n                         :coli coli\n                         :colj colj\n                         :corr corr\n                         :corr-round (round corr 2 :HALF_EVEN)})))))))\n         (apply concat)\n         tc/dataset)))\n\nFor example:\n\n(-&gt; noj-book.datasets/iris\n    (correlations-dataset [:sepal-length :sepal-width :petal-length :petal-width]))\n\n\n_unnamed [16 6]:\n\n\n\n:i\n:j\n:coli\n:colj\n:corr\n:corr-round\n\n\n\n\n0\n0\n:sepal-length\n:sepal-length\n1.00000000\n1.000\n\n\n0\n1\n:sepal-length\n:sepal-width\n-0.11756978\n-0.1200\n\n\n0\n2\n:sepal-length\n:petal-length\n0.87175378\n0.8700\n\n\n0\n3\n:sepal-length\n:petal-width\n0.81794113\n0.8200\n\n\n1\n0\n:sepal-width\n:sepal-length\n-0.11756978\n-0.1200\n\n\n1\n1\n:sepal-width\n:sepal-width\n1.00000000\n1.000\n\n\n1\n2\n:sepal-width\n:petal-length\n-0.42844010\n-0.4300\n\n\n1\n3\n:sepal-width\n:petal-width\n-0.36612593\n-0.3700\n\n\n2\n0\n:petal-length\n:sepal-length\n0.87175378\n0.8700\n\n\n2\n1\n:petal-length\n:sepal-width\n-0.42844010\n-0.4300\n\n\n2\n2\n:petal-length\n:petal-length\n1.00000000\n1.000\n\n\n2\n3\n:petal-length\n:petal-width\n0.96286543\n0.9600\n\n\n3\n0\n:petal-width\n:sepal-length\n0.81794113\n0.8200\n\n\n3\n1\n:petal-width\n:sepal-width\n-0.36612593\n-0.3700\n\n\n3\n2\n:petal-width\n:petal-length\n0.96286543\n0.9600\n\n\n3\n3\n:petal-width\n:petal-width\n1.00000000\n1.000",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Visualizing correlation matrices (experimental üõ†) - DRAFT</span>"
    ]
  },
  {
    "objectID": "noj_book.visualizing_correlation_matrices.html#drawing-a-heatmap-using-echarts",
    "href": "noj_book.visualizing_correlation_matrices.html#drawing-a-heatmap-using-echarts",
    "title": "10¬† Visualizing correlation matrices (experimental üõ†) - DRAFT",
    "section": "10.3 Drawing a heatmap using Echarts",
    "text": "10.3 Drawing a heatmap using Echarts\nThe following function is inspired by an Apache Echarts heatmap tutorial.\n\n(defn echarts-heatmap [{:keys [xyz-data xs ys\n                               min max\n                               series-name]\n                        :or {series-name \"\"}}]\n  (kind/echarts\n   {:tooltip {}\n    :xAxis {:type :category\n            :data xs}\n    :yAxis {:type :category\n            :data ys}\n    :visualMap {:min min\n                :max max\n                :calculable true\n                :splitNumber 8\n                :inRange {:color\n                          [\"#313695\" \"#4575b4\" \"#74add1\"\n                           \"#abd9e9\" \"#e0f3f8\" \"#ffffbf\"\n                           \"#fee090\" \"#fdae61\" \"#f46d43\"\n                           \"#d73027\" \"#a50026\"]}}\n    :series [{:name series-name\n              :type :heatmap\n              :data xyz-data\n              :itemStyle {:emphasis {:borderColor \"#333\"\n                                     :borderWidth 2}}\n              :progressive 1000\n              :animation false}]}))\n\nHere is an example using synthetic data:\n\n(let [n 30]\n  (echarts-heatmap\n   {:xyz-data (for [i (range n)\n                    j (range n)]\n                [i j (fastmath/logistic (*  (+ (- i j))\n                                            (rand)\n                                            (/ 2 (double n))))])\n    :x-data (range n)\n    :y-data (range n)\n    :min 0\n    :max 1}))\n\n\nNote the slider control and the tooltips.\nHere is an example with an actual correlation matrix.\n\n(let [columns-for-correlations [:sepal-length :sepal-width\n                                :petal-length :petal-width]\n      correlations (-&gt; noj-book.datasets/iris\n                       (correlations-dataset columns-for-correlations)\n                       (tc/select-columns [:coli :colj :corr-round])\n                       tc/rows)]\n  (echarts-heatmap {:xyz-data correlations\n                    :xs columns-for-correlations\n                    :ys columns-for-correlations\n                    :min -1\n                    :max 1\n                    :series-name \"correlation\"}))\n\n\nTODO: Improve the layout so that the slider control does not overlap the labels.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Visualizing correlation matrices (experimental üõ†) - DRAFT</span>"
    ]
  },
  {
    "objectID": "noj_book.visualizing_correlation_matrices.html#drawing-a-heatmap-using-cljplot",
    "href": "noj_book.visualizing_correlation_matrices.html#drawing-a-heatmap-using-cljplot",
    "title": "10¬† Visualizing correlation matrices (experimental üõ†) - DRAFT",
    "section": "10.4 Drawing a heatmap using cljplot",
    "text": "10.4 Drawing a heatmap using cljplot\ncoming soon",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Visualizing correlation matrices (experimental üõ†) - DRAFT</span>"
    ]
  },
  {
    "objectID": "noj_book.visualizing_correlation_matrices.html#drawing-a-heatmap-using-vega",
    "href": "noj_book.visualizing_correlation_matrices.html#drawing-a-heatmap-using-vega",
    "title": "10¬† Visualizing correlation matrices (experimental üõ†) - DRAFT",
    "section": "10.5 Drawing a heatmap using Vega",
    "text": "10.5 Drawing a heatmap using Vega\ncoming soon\n\nsource: notebooks/noj_book/visualizing_correlation_matrices.clj",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Visualizing correlation matrices (experimental üõ†) - DRAFT</span>"
    ]
  }
]